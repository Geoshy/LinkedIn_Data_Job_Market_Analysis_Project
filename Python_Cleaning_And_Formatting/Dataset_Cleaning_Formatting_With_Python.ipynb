{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d469e3",
   "metadata": {},
   "source": [
    "## **Data Cleaning And Formatting With Python:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2abbd1",
   "metadata": {},
   "source": [
    "### **Import Important Libraries And Modules:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7471c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bdd39",
   "metadata": {},
   "source": [
    "### **Export The CSV File Of The Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc76035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\IT Courses\\\\Finished Courses\\\\LinkedIn Job Market Analysis Project\\\\LinkedIn_Data_Job_Market_Analysis_Project\\\\Dataset\\\\clean_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f1e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               327 non-null    int64  \n",
      " 1   title            327 non-null    object \n",
      " 2   company          327 non-null    object \n",
      " 3   location         327 non-null    object \n",
      " 4   link             327 non-null    object \n",
      " 5   source           327 non-null    object \n",
      " 6   date_posted      327 non-null    object \n",
      " 7   work_type        0 non-null      float64\n",
      " 8   employment_type  0 non-null      float64\n",
      " 9   description      327 non-null    object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dab38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9e740",
   "metadata": {},
   "source": [
    "### **Data Cleaning & Formatting:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc01f8d",
   "metadata": {},
   "source": [
    "**1. Remove Nan Values Columns & \"link\" Column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46858b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.drop(\n",
    "    ['work_type', 'employment_type', 'link'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678e7aa",
   "metadata": {},
   "source": [
    "**2. Change Data Type Of Column \"date_posted\" To Datatime Data Type:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18514cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['date_posted'] = pd.to_datetime(df_copy['date_posted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241fabe",
   "metadata": {},
   "source": [
    "**3. Remove Duplicated Rows:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d688012c",
   "metadata": {},
   "source": [
    "**3.1. Explore Number Of Duplicated Rows With Same Columns Values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b55ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(df_copy.duplicated().sum()) # 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cf7af",
   "metadata": {},
   "source": [
    "**3.2. Explore If There Duplicated Row With Same Values Of (Title - Company - Location)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6734ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplocated_rows = df_copy[df_copy.duplicated(['title', 'company', 'location'], keep=False)].sort_values(by=['title', 'company', 'location'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae6f7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplocated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea986f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>111</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Explore Group</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Data Analyst\\n\\n***MUST HAVE MARITIME EXPERIEN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>128</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Explore Group</td>\n",
       "      <td>London Area, United Kingdom</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Senior Data Analyst – Maritime Industry Focus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>110</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PT Indofood CBP Sukses Makmur Tbk - Noodle Div...</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Persyaratan Pekerjaan\\n\\n\\nHave advance skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>112</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>PT Indofood CBP Sukses Makmur Tbk - Noodle Div...</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Persyaratan Pekerjaan\\n\\n\\nMemiliki gelar sarj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>653</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>Job Description:\\nDevelop/enhance data warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>654</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>Job Description:\\nDevelop/enhance data warehou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          title                                            company  \\\n",
       "67   111   Data Analyst                                      Explore Group   \n",
       "79   128   Data Analyst                                      Explore Group   \n",
       "66   110   Data Analyst  PT Indofood CBP Sukses Makmur Tbk - Noodle Div...   \n",
       "68   112   Data Analyst  PT Indofood CBP Sukses Makmur Tbk - Noodle Div...   \n",
       "290  653  Data Engineer                                    Thomson Reuters   \n",
       "291  654  Data Engineer                                    Thomson Reuters   \n",
       "\n",
       "                        location    source date_posted  \\\n",
       "67   London Area, United Kingdom  LinkedIn  2025-04-15   \n",
       "79   London Area, United Kingdom  LinkedIn  2025-04-16   \n",
       "66   Jakarta, Jakarta, Indonesia  LinkedIn  2025-04-16   \n",
       "68   Jakarta, Jakarta, Indonesia  LinkedIn  2025-04-16   \n",
       "290  Bengaluru, Karnataka, India  LinkedIn  2025-04-11   \n",
       "291  Bengaluru, Karnataka, India  LinkedIn  2025-04-11   \n",
       "\n",
       "                                           description  \n",
       "67   Data Analyst\\n\\n***MUST HAVE MARITIME EXPERIEN...  \n",
       "79   Senior Data Analyst – Maritime Industry Focus ...  \n",
       "66   Persyaratan Pekerjaan\\n\\n\\nHave advance skills...  \n",
       "68   Persyaratan Pekerjaan\\n\\n\\nMemiliki gelar sarj...  \n",
       "290  Job Description:\\nDevelop/enhance data warehou...  \n",
       "291  Job Description:\\nDevelop/enhance data warehou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplocated_rows.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e551f3",
   "metadata": {},
   "source": [
    "**We identified duplicate job postings with matching titles, companies, and locations but varying descriptions. This likely indicates either:**\n",
    "\n",
    "**1. The same job listed across multiple LinkedIn sections (e.g., search results and recommendations).**\n",
    "\n",
    "**2. Updated versions of the original posting with modified descriptions.**\n",
    "\n",
    "**So, we will remove this duplicated rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19985fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.drop(duplocated_rows.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd64f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 288 entries, 0 to 326\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   id           288 non-null    int64         \n",
      " 1   title        288 non-null    object        \n",
      " 2   company      288 non-null    object        \n",
      " 3   location     288 non-null    object        \n",
      " 4   source       288 non-null    object        \n",
      " 5   date_posted  288 non-null    datetime64[ns]\n",
      " 6   description  288 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a434c",
   "metadata": {},
   "source": [
    "**4.  Create Column \"job_title_short\" From Column \"title\" For General Data Jobs Titles Classification In Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec98d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082f23c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst', 'Data Analyst II',\n",
       "       'Data Analyst, Production Finance Operations & Innovation',\n",
       "       'Data Analyst - Marketing',\n",
       "       'Data Analyst, Global Partnerships & Content',\n",
       "       'Senior Data Analyst', 'Data Products Analyst, YouTube',\n",
       "       'Customer Relationship Management Analyst',\n",
       "       'Data Analyst - SQL, ERP', 'Marketing Data Analyst',\n",
       "       'Analytics Associate', 'Data Analyst I',\n",
       "       'Data & Analytics, Analyst', 'Junior Data Analyst - Remote',\n",
       "       'People Data Analyst', 'Customer Insights Analyst',\n",
       "       'Data Analyst Intern (Fall start)', 'Analyst, Data Science, RMBS',\n",
       "       'Analyst', 'Business Data Analyst', 'Junior Data Analyst',\n",
       "       'Healthcare Data Analyst I - Remote', 'Data Analyst - 100% Remote',\n",
       "       'Insights Analyst', 'Sr. Data Analyst', 'Data Analyst Contractor',\n",
       "       'Analyst, Data Analytics & Intelligence',\n",
       "       'Analista de Dados Junior - São Paulo/SP',\n",
       "       'Data Platform Analyst, Subscriptions', 'Healthcare Data Analyst',\n",
       "       'Junior Data Analyst UK&I', 'Lead Data Analyst (Power BI,SQL)',\n",
       "       'Officer - Real Time Analytics',\n",
       "       'ANALISTA GESTAO DE INDICADORES PL', 'DATA ANALYST I',\n",
       "       'Data Analytics', 'Analista de Dados Júnior | Data Viz',\n",
       "       'Analyst-Data Science', 'Analyst, Data Science',\n",
       "       'Data Analyst Intern', 'Analista de Dados Júnior',\n",
       "       'Sr Data Analyst', 'Data Analyst (Data Visualization)',\n",
       "       'Analista de Business Intelligence Júnior',\n",
       "       'Data Associate - Gurgaon',\n",
       "       'Data Analyst - Local to Pittsburgh or Cleveland',\n",
       "       'Analista de Análise de Dados Junior', 'Data analyst',\n",
       "       'Data Intern', 'Jr. Data & BI Analyst',\n",
       "       'Data Scientist, Product, Sustainability',\n",
       "       'Data Scientist, Product Analytics', 'Fraud Data Scientist',\n",
       "       'Senior Data Scientist', 'Data Scientist',\n",
       "       'Machine Learning Engineer (L5) - Content & Media ML Foundations',\n",
       "       'Data Scientist - Last Mile',\n",
       "       'Partner Data Scientist, Growth Partnerships',\n",
       "       'Jr. Data Scientist', 'Data Scientist, Marketing Science',\n",
       "       'AI/ML Engineer',\n",
       "       'Data Scientist- Customer Lifecycle and Engagement',\n",
       "       'Cientista de Dados II - Área Prevenção a Fraudes',\n",
       "       'Graduate Data Scientist',\n",
       "       'Staff Data Scientist, Strategy & Insights', 'Data Scientist I',\n",
       "       'Data Scientist/Analyst', 'GEN AI/ML',\n",
       "       'Data Scientist, Fundamental Sector Data',\n",
       "       'Machine Learning Engineer (Berlin, Germany)',\n",
       "       'Data Scientist (L5) - App QoE',\n",
       "       'Data Scientist (Business Operations)',\n",
       "       'Junior Artificial Intelligence (AI) / Machine Learning (ML) Engineer',\n",
       "       'Junior Frontend Developer',\n",
       "       'Data Scientist (Climate & Geospatial)', 'Data Scientist Jr.',\n",
       "       'Cientista de Dados - Estágio', 'Machine Learning Engineer',\n",
       "       'Data Scientist (Entry Level)', 'Product Data Scientist',\n",
       "       'Research And Development Scientist',\n",
       "       'Data Scientist Senior - MLOps & Transformation (F/H)',\n",
       "       'Junior Data Scientist', 'Data Scientist-1',\n",
       "       'Data Scientist Strategy & Value Creation Consulting',\n",
       "       'Data Scientist (m/f/d)', 'Data Scientist (AI/ML)',\n",
       "       'Data Scientist/Sr Data Scientist',\n",
       "       'Machine Learning Engineer (Junior)', 'AI/ML Developer',\n",
       "       'AI/ML Researcher',\n",
       "       'Data Scientist, Consumer Research & Marketing',\n",
       "       'Data Scientist, Marketing', 'AI Engineer',\n",
       "       'Data Scientist III, Product, Operations Data Science',\n",
       "       'Machine Learning Software Engineer (L5) - Content and Studio',\n",
       "       'Data Scientist III (Commercial Analytics)',\n",
       "       'Data Engineer (L5) - Conversation',\n",
       "       'Data Engineer (L4) - Security', 'Data Engineer',\n",
       "       'Data Engineer, Play Data Science and Analytics',\n",
       "       'Data Engineer, Infrastructure',\n",
       "       'ML Software Engineer (L4/L5) - Media Algorithms',\n",
       "       'Analytics Engineer (L4) - Acquisition',\n",
       "       'Data Engineer, Product Analytics',\n",
       "       'Data Engineer I (Full Time) United States',\n",
       "       'Software Engineer L4, Machine Learning Platform (Metaflow)',\n",
       "       'Software Engineer 5, Data Clean Room', 'Senior Data Engineer',\n",
       "       'Data Engineer Graduate (Ads Data Application) - 2025 Start (BS/MS)',\n",
       "       'Senior, Data Engineer',\n",
       "       'Software Engineer, AI Platform - New Grad',\n",
       "       'Data Engineer - People Analytics', 'Data Engineer, E-Commerce',\n",
       "       'Data Engineer, VX Analytics', 'Sr. Data Engineer',\n",
       "       'Data Engineer III',\n",
       "       'Data Engineer, Analytics (Technical Leadership)',\n",
       "       'Remote Engineer, Data, I', 'Sr. Data Engineer, Analytics',\n",
       "       'Data Engineer Jr.', 'Data Engineer - Subscriptions',\n",
       "       'Data Engineer, Digital Acceleration', '(USA) Data Engineer III',\n",
       "       'Data Engineer (University Grad)', 'Data Engineer I, IN-Ads',\n",
       "       'Data Engineer - Python', 'Data Engineer with Python + SQL',\n",
       "       'Data Engineer, Marketplace', 'UK 2025 Data Engineer Internship',\n",
       "       'Infrastructure Partner Data Engineer',\n",
       "       'Infrastructure Partner Data Engineer, YouTube',\n",
       "       'Infrastructure Partner Data Engineer, Youtube',\n",
       "       'Data Operation Engineer I', 'Data Engineer(AWS)',\n",
       "       'Associate Data Engineer', 'Data Engineer - C10',\n",
       "       'Data Engineer - Commerce Platform',\n",
       "       'Data Engineer - Enterprise Data Operations Analyst',\n",
       "       'Jr. Data Engineer', 'Data Engineer - C11',\n",
       "       'Python & SQL Data Engineer_Director_Software Engineering',\n",
       "       'Senior Software Engineer, Systems Infrastructure',\n",
       "       'Data Analytics Engineer', 'Data Engineer (Platform)',\n",
       "       'Data Engineer- Python Pyspark', 'Data Engineer with Pyspark',\n",
       "       'Data Engineer I'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3649efa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Data Analyst                                            49\n",
       "Data Engineer                                           27\n",
       "Data Scientist                                          23\n",
       "Data Engineer, Product Analytics                        11\n",
       "Machine Learning Engineer                                9\n",
       "Data Scientist, Product Analytics                        5\n",
       "Data Products Analyst, YouTube                           4\n",
       "Data Analyst I                                           3\n",
       "Business Data Analyst                                    3\n",
       "Data Analyst II                                          3\n",
       "Data Engineer I (Full Time) United States                2\n",
       "Senior Data Analyst                                      2\n",
       "Junior Data Analyst                                      2\n",
       "Data Scientist, Product, Sustainability                  2\n",
       "Healthcare Data Analyst                                  2\n",
       "Data Scientist III, Product, Operations Data Science     2\n",
       "Data Engineer, E-Commerce                                2\n",
       "Data Engineer III                                        2\n",
       "Data Scientist I                                         2\n",
       "Senior Data Scientist                                    2\n",
       "Data Engineer, Analytics (Technical Leadership)          2\n",
       "Sr. Data Analyst                                         2\n",
       "Data Analytics                                           2\n",
       "Analyst, Data Science, RMBS                              1\n",
       "Junior Data Analyst - Remote                             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['title'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db747e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyst_roles = list(df_copy['title'][df_copy['title'].str.contains('Data Analyst')].unique())\n",
    "\n",
    "data_analyst_roles_2 = [\n",
    "    'Data & Analytics, Analyst', 'DATA ANALYST I', 'Data analyst',\n",
    "    'Analyst, Data Analytics & Intelligence', 'Data Analytics',\n",
    "    'Analista de Business Intelligence Júnior',\n",
    "    'Analista de Análise de Dados Junior',\n",
    "    'Jr. Data & BI Analyst',\n",
    "    'Data Products Analyst, YouTube',\n",
    "    'Customer Relationship Management Analyst'\n",
    "    ]\n",
    "\n",
    "data_analyst_roles.extend(data_analyst_roles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b03d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_engineer_roles = list(df_copy['title'][df_copy['title'].str.contains('Data Engineer')].unique())\n",
    "\n",
    "data_engineer_roles_2 = ['Remote Engineer, Data, I', 'Data Operation Engineer I']\n",
    "\n",
    "data_engineer_roles.extend(data_engineer_roles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa51b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scientist_roles = list(df_copy['title'][df_copy['title'].str.contains('Data Scientist')].unique())\n",
    "data_scientist_roles_2 = ['Cientista de Dados II - Área Prevenção a Fraudes', 'Cientista de Dados - Estágio']\n",
    "\n",
    "data_scientist_roles.extend(data_scientist_roles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "455acce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_engineer_roles = list(df_copy['title'][df_copy['title'].str.contains('Machine Learning Engineer')].unique())\n",
    "\n",
    "machine_learning_engineer_roles_2 = [\n",
    "    'AI/ML Engineer', 'Junior Artificial Intelligence (AI) / Machine ...',\n",
    "    'AI/ML Researcher', 'Machine Learning Software Engineer (L5) - Cont...',\n",
    "    'ML Software Engineer (L4/L5) - Media Algorithms',\n",
    "    'Software Engineer L4, Machine Learning Platfor..'\n",
    "    ]\n",
    "\n",
    "machine_learning_engineer_roles.extend(machine_learning_engineer_roles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b67d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_title_short_func(title):\n",
    "        for role in data_analyst_roles:\n",
    "            if title.strip() == role:\n",
    "                return('Data Analyst')\n",
    "            \n",
    "        for role in data_engineer_roles:\n",
    "            if title.strip() == role:\n",
    "                return('Data Engineer')\n",
    "        \n",
    "        for role in data_scientist_roles:\n",
    "            if title.strip() == role:\n",
    "                return('Data Scientist')\n",
    "        \n",
    "        for role in machine_learning_engineer_roles:\n",
    "            if title.strip() == role:\n",
    "                return('Machine Learning Engineer')\n",
    "        \n",
    "        else:\n",
    "            return('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736d2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['job_title_short'] = df_copy['title'].apply(job_title_short_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a2217c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>89</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Ignite Digital Services</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>Are you searching for an opportunity to take y...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>449</td>\n",
       "      <td>Machine Learning Engineer (Junior)</td>\n",
       "      <td>LogicMatrix</td>\n",
       "      <td>Florida, United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-17</td>\n",
       "      <td>Machine Learning Engineer (Junior)\\n\\n\\n\\nA Bi...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>443</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sigma Suisse</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Sigma Suisse is seeking for it's client, a com...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>81</td>\n",
       "      <td>Data Analyst - 100% Remote</td>\n",
       "      <td>Lensa</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Lensa is the leading career site for job seeke...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>242</td>\n",
       "      <td>Analista de Análise de Dados Junior</td>\n",
       "      <td>C6 Bank</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Nossa área de análise de dados\\n\\nO time de an...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>130</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>EY</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>At EY, you’ll have the chance to build a caree...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>407</td>\n",
       "      <td>GEN AI/ML</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>At Nielsen, we are passionate about our work t...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>69</td>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Colibri Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>At Colibri, culture is a critical part of our ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>286</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Redwood Materials</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>About Redwood Materials\\n\\nRedwood Materials w...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>586</td>\n",
       "      <td>Analytics Engineer (L4) - Acquisition</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>Los Gatos, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Netflix is one of the world's leading entertai...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>142</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>AARATECH</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Overview:\\n\\nThe Data Analyst is tasked with c...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35</td>\n",
       "      <td>Data Analyst - SQL, ERP</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Yakima, WA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Data Analyst\\n\\nLocation: Remote\\n\\nPosition O...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>671</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Samba TV</td>\n",
       "      <td>Amsterdam, North Holland, Netherlands</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Samba TV tracks streaming and broadcast video ...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>390</td>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>Matlen Silver</td>\n",
       "      <td>United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Title: Junior Data Scientist\\n\\nContract Durat...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>FinThrive</td>\n",
       "      <td>United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>About the Role\\n\\nImpact you will make\\n\\nAs a...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>616</td>\n",
       "      <td>Data Engineer, Product Analytics</td>\n",
       "      <td>Meta</td>\n",
       "      <td>United States</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>As a Data Engineer at Meta, you will shape the...</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>83</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>AARATECH</td>\n",
       "      <td>New York City Metropolitan Area</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Overview:\\n\\nThe Data Analyst is tasked with c...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>145</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Searchability®</td>\n",
       "      <td>Nottingham, England, United Kingdom</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Data Analyst – 12 MONTH FTC\\n\\n\\n\\n\\nOpportuni...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>82</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Equiliem</td>\n",
       "      <td>Lexington, MA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>MUST HAVE SECRET CLEARANCE OR BE ABLE TO OBTAI...</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>448</td>\n",
       "      <td>Data Scientist/Sr Data Scientist</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Intro\\n\\nAre you ready to explore a world of p...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                  title                  company  \\\n",
       "53    89                           Data Analyst  Ignite Digital Services   \n",
       "185  449     Machine Learning Engineer (Junior)              LogicMatrix   \n",
       "179  443                         Data Scientist             Sigma Suisse   \n",
       "45    81             Data Analyst - 100% Remote                    Lensa   \n",
       "104  242    Analista de Análise de Dados Junior                  C6 Bank   \n",
       "80   130                         Data Analytics                       EY   \n",
       "146  407                              GEN AI/ML               technology   \n",
       "33    69                         Data Analyst I            Colibri Group   \n",
       "109  286                           Data Analyst        Redwood Materials   \n",
       "231  586  Analytics Engineer (L4) - Acquisition                  Netflix   \n",
       "90   142                           Data Analyst                 AARATECH   \n",
       "17    35                Data Analyst - SQL, ERP              CyberCoders   \n",
       "307  671                          Data Engineer                 Samba TV   \n",
       "129  390                     Jr. Data Scientist            Matlen Silver   \n",
       "13    30                           Data Analyst                FinThrive   \n",
       "261  616       Data Engineer, Product Analytics                     Meta   \n",
       "47    83                           Data Analyst                 AARATECH   \n",
       "93   145                           Data Analyst           Searchability®   \n",
       "46    82                           Data Analyst                 Equiliem   \n",
       "184  448       Data Scientist/Sr Data Scientist        American Airlines   \n",
       "\n",
       "                                  location    source date_posted  \\\n",
       "53                           San Diego, CA  LinkedIn  2025-04-10   \n",
       "185                 Florida, United States  LinkedIn  2025-04-17   \n",
       "179                    Geneva, Switzerland  LinkedIn  2025-04-16   \n",
       "45                        Jacksonville, FL  LinkedIn  2025-04-16   \n",
       "104           São Paulo, São Paulo, Brazil  LinkedIn  2025-04-15   \n",
       "80                Gurugram, Haryana, India  LinkedIn  2025-04-15   \n",
       "146            Bengaluru, Karnataka, India  LinkedIn  2025-04-16   \n",
       "33                           United States  LinkedIn  2025-04-11   \n",
       "109                      San Francisco, CA  LinkedIn  2025-04-16   \n",
       "231                          Los Gatos, CA  LinkedIn  2025-04-16   \n",
       "90               California, United States  LinkedIn  2025-04-16   \n",
       "17                              Yakima, WA  LinkedIn  2025-04-15   \n",
       "307  Amsterdam, North Holland, Netherlands  LinkedIn  2025-04-15   \n",
       "129                          United States  LinkedIn  2025-04-16   \n",
       "13                           United States  LinkedIn  2025-04-15   \n",
       "261                          United States  LinkedIn  2025-04-14   \n",
       "47         New York City Metropolitan Area  LinkedIn  2025-04-14   \n",
       "93     Nottingham, England, United Kingdom  LinkedIn  2025-04-16   \n",
       "46                           Lexington, MA  LinkedIn  2025-04-16   \n",
       "184                             Dallas, TX  LinkedIn  2025-04-15   \n",
       "\n",
       "                                           description  \\\n",
       "53   Are you searching for an opportunity to take y...   \n",
       "185  Machine Learning Engineer (Junior)\\n\\n\\n\\nA Bi...   \n",
       "179  Sigma Suisse is seeking for it's client, a com...   \n",
       "45   Lensa is the leading career site for job seeke...   \n",
       "104  Nossa área de análise de dados\\n\\nO time de an...   \n",
       "80   At EY, you’ll have the chance to build a caree...   \n",
       "146  At Nielsen, we are passionate about our work t...   \n",
       "33   At Colibri, culture is a critical part of our ...   \n",
       "109  About Redwood Materials\\n\\nRedwood Materials w...   \n",
       "231  Netflix is one of the world's leading entertai...   \n",
       "90   Overview:\\n\\nThe Data Analyst is tasked with c...   \n",
       "17   Data Analyst\\n\\nLocation: Remote\\n\\nPosition O...   \n",
       "307  Samba TV tracks streaming and broadcast video ...   \n",
       "129  Title: Junior Data Scientist\\n\\nContract Durat...   \n",
       "13   About the Role\\n\\nImpact you will make\\n\\nAs a...   \n",
       "261  As a Data Engineer at Meta, you will shape the...   \n",
       "47   Overview:\\n\\nThe Data Analyst is tasked with c...   \n",
       "93   Data Analyst – 12 MONTH FTC\\n\\n\\n\\n\\nOpportuni...   \n",
       "46   MUST HAVE SECRET CLEARANCE OR BE ABLE TO OBTAI...   \n",
       "184  Intro\\n\\nAre you ready to explore a world of p...   \n",
       "\n",
       "               job_title_short  \n",
       "53                Data Analyst  \n",
       "185  Machine Learning Engineer  \n",
       "179             Data Scientist  \n",
       "45                Data Analyst  \n",
       "104               Data Analyst  \n",
       "80                Data Analyst  \n",
       "146                      Other  \n",
       "33                Data Analyst  \n",
       "109               Data Analyst  \n",
       "231                      Other  \n",
       "90                Data Analyst  \n",
       "17                Data Analyst  \n",
       "307              Data Engineer  \n",
       "129             Data Scientist  \n",
       "13                Data Analyst  \n",
       "261              Data Engineer  \n",
       "47                Data Analyst  \n",
       "93                Data Analyst  \n",
       "46                Data Analyst  \n",
       "184             Data Scientist  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c464d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title_short\n",
       "Data Analyst                 97\n",
       "Data Engineer                84\n",
       "Data Scientist               64\n",
       "Other                        28\n",
       "Machine Learning Engineer    15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['job_title_short'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9f5e1",
   "metadata": {},
   "source": [
    "**5. Import The Exported Excel Files Containing The New Columns as Separate Dataframes, Which are Then Merged With The Main Dataframe.:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd2c98",
   "metadata": {},
   "source": [
    "**(1) Import The Exported Excel Files:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8755336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_dfs_list = []\n",
    "index = 1\n",
    "\n",
    "while index < 5:\n",
    "    df_skills = pd.read_excel(\n",
    "        f'D:\\\\IT Courses\\\\Finished Courses\\\\LinkedIn Job Market Analysis Project\\\\LinkedIn_Data_Job_Market_Analysis_Project\\\\Dataset\\\\extract_columns_from_description_{index}.xlsx',\n",
    "        usecols=['id', 'skills', 'work_type', 'educational_background', 'experience_years']\n",
    "    )\n",
    "    skills_dfs_list.append(df_skills)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6e47521",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = skills_dfs_list[0]\n",
    "\n",
    "for skill_df in skills_dfs_list[1:]:\n",
    "    skills_df = pd.concat(\n",
    "        [\n",
    "        skills_df,\n",
    "        skill_df\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b24d496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df['skills'] = skills_df['skills'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1772772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>skills</th>\n",
       "      <th>work_type</th>\n",
       "      <th>educational_background</th>\n",
       "      <th>experience_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Python', 'SQL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>691</td>\n",
       "      <td>['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>7+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>692</td>\n",
       "      <td>['SQL', 'Spark', 'AWS', 'ETL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>14+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>693</td>\n",
       "      <td>['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...</td>\n",
       "      <td>remote</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>740</td>\n",
       "      <td>['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>741</td>\n",
       "      <td>['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                             skills work_type  \\\n",
       "0     1  ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "1     2  ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "2     3  ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "3     4  ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "4     5                                  ['Python', 'SQL']       NaN   \n",
       "..  ...                                                ...       ...   \n",
       "50  691  ['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...       NaN   \n",
       "51  692                     ['SQL', 'Spark', 'AWS', 'ETL']       NaN   \n",
       "52  693  ['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...    remote   \n",
       "53  740  ['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...       NaN   \n",
       "54  741  ['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...       NaN   \n",
       "\n",
       "    educational_background experience_years  \n",
       "0                     True               4+  \n",
       "1                     True               4+  \n",
       "2                     True               4+  \n",
       "3                     True               4+  \n",
       "4                     True               4+  \n",
       "..                     ...              ...  \n",
       "50                   False               7+  \n",
       "51                   False              14+  \n",
       "52                    True              NaN  \n",
       "53                    True               3+  \n",
       "54                    True               1+  \n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674407f7",
   "metadata": {},
   "source": [
    "**(2) Merge (Join) Skills Dataframe With Main Dataframe By Column \"Id\"::**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7444d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.merge(\n",
    "        df_copy,\n",
    "        skills_df,\n",
    "        how='inner',\n",
    "        on='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3991d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>skills</th>\n",
       "      <th>work_type</th>\n",
       "      <th>educational_background</th>\n",
       "      <th>experience_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>About Pinterest\\n\\nMillions of people around t...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Python', 'SQL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>691</td>\n",
       "      <td>Data Engineer- Python Pyspark</td>\n",
       "      <td>Virtusa</td>\n",
       "      <td>Chennai, Tamil Nadu, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>7+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>692</td>\n",
       "      <td>Data Engineer with Pyspark</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>Job Title:- Data Engineer with Pyspark\\n\\nLoca...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['SQL', 'Spark', 'AWS', 'ETL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>14+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>693</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mercedes-Benz Malaysia</td>\n",
       "      <td>Puchong, Selangor, Malaysia</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...</td>\n",
       "      <td>remote</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>740</td>\n",
       "      <td>Data Engineer I</td>\n",
       "      <td>IntePros</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Data Engineer I – Infrastructure &amp; Automation ...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>741</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Snap Inc is a technology company. We believe t...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                          title                 company  \\\n",
       "0      1                   Data Analyst                    Meta   \n",
       "1      2                   Data Analyst                    Meta   \n",
       "2      3                   Data Analyst                    Meta   \n",
       "3      4                   Data Analyst                    Meta   \n",
       "4      5                Data Analyst II               Pinterest   \n",
       "..   ...                            ...                     ...   \n",
       "283  691  Data Engineer- Python Pyspark                 Virtusa   \n",
       "284  692     Data Engineer with Pyspark               Cognizant   \n",
       "285  693                  Data Engineer  Mercedes-Benz Malaysia   \n",
       "286  740                Data Engineer I                IntePros   \n",
       "287  741                  Data Engineer               Snap Inc.   \n",
       "\n",
       "                              location    source date_posted  \\\n",
       "0                         New York, NY  LinkedIn  2025-04-14   \n",
       "1                    San Francisco, CA  LinkedIn  2025-04-14   \n",
       "2                      Los Angeles, CA  LinkedIn  2025-04-14   \n",
       "3                       Washington, DC  LinkedIn  2025-04-14   \n",
       "4                          Chicago, IL  LinkedIn  2025-04-16   \n",
       "..                                 ...       ...         ...   \n",
       "283         Chennai, Tamil Nadu, India  LinkedIn  2025-04-10   \n",
       "284  Bangalore Urban, Karnataka, India  LinkedIn  2025-04-13   \n",
       "285        Puchong, Selangor, Malaysia  LinkedIn  2025-04-16   \n",
       "286                        Seattle, WA  LinkedIn  2025-04-15   \n",
       "287                       Bellevue, WA  LinkedIn  2025-04-16   \n",
       "\n",
       "                                           description job_title_short  \\\n",
       "0    The Social Measurement team is a growing team ...    Data Analyst   \n",
       "1    The Social Measurement team is a growing team ...    Data Analyst   \n",
       "2    The Social Measurement team is a growing team ...    Data Analyst   \n",
       "3    The Social Measurement team is a growing team ...    Data Analyst   \n",
       "4    About Pinterest\\n\\nMillions of people around t...    Data Analyst   \n",
       "..                                                 ...             ...   \n",
       "283  Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...   Data Engineer   \n",
       "284  Job Title:- Data Engineer with Pyspark\\n\\nLoca...   Data Engineer   \n",
       "285  About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...   Data Engineer   \n",
       "286  Data Engineer I – Infrastructure & Automation ...   Data Engineer   \n",
       "287  Snap Inc is a technology company. We believe t...   Data Engineer   \n",
       "\n",
       "                                                skills work_type  \\\n",
       "0    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "1    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "2    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "3    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "4                                    ['Python', 'SQL']       NaN   \n",
       "..                                                 ...       ...   \n",
       "283  ['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...       NaN   \n",
       "284                     ['SQL', 'Spark', 'AWS', 'ETL']       NaN   \n",
       "285  ['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...    remote   \n",
       "286  ['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...       NaN   \n",
       "287  ['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...       NaN   \n",
       "\n",
       "     educational_background experience_years  \n",
       "0                      True               4+  \n",
       "1                      True               4+  \n",
       "2                      True               4+  \n",
       "3                      True               4+  \n",
       "4                      True               4+  \n",
       "..                      ...              ...  \n",
       "283                   False               7+  \n",
       "284                   False              14+  \n",
       "285                    True              NaN  \n",
       "286                    True               3+  \n",
       "287                    True               1+  \n",
       "\n",
       "[288 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d0db7",
   "metadata": {},
   "source": [
    "**7. Remove Column \"description\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f1f3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.drop(\n",
    "    ['description'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce01adf",
   "metadata": {},
   "source": [
    "**8. Create Column \"country\" From \"location\":**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a561876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_unique = list(df_copy['location'].unique())\n",
    "len(location_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36566071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_state_abbreviations = \"United States|united states|USA|usa|AL|AK|AZ|AR|CA|CO|CT|DE|FL|GA|HI|ID|IL|IN|IA|KS|KY|LA|ME|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC|ND|OH|OK|OR|PA|RI|SC|SD|TN|TX|UT|VT|VA|WA|WV|WI|WY|New York City Metropolitan Area|Washington DC-Baltimore Area|California|San Francisco Bay Area|Greater Minneapolis-St. Paul Area|DC\"\n",
    "\n",
    "usa_list = list(df_copy['location'][df_copy['location'].str.contains(usa_state_abbreviations)].unique())\n",
    "len(usa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab4c5aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_list = list(df_copy['location'][df_copy['location'].str.contains('India')].unique())\n",
    "len(india_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50744908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_list = list(df_copy['location'][df_copy['location'].str.contains('United Kingdom')].unique())\n",
    "len(uk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a012cd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brazil_list = list(df_copy['location'][df_copy['location'].str.contains('Brazil|Greater Rio de Janeiro')].unique())\n",
    "len(brazil_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8268b6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spain_list = list(df_copy['location'][df_copy['location'].str.contains('Spain')].unique())\n",
    "len(spain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c6da896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canda_list = list(df_copy['location'][df_copy['location'].str.contains('Canada')].unique())\n",
    "len(canda_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2153939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indonesia_list = list(df_copy['location'][df_copy['location'].str.contains('Indonesia')].unique())\n",
    "len(indonesia_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ireland_list = list(df_copy['location'][df_copy['location'].str.contains('Ireland')].unique())\n",
    "len(ireland_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "508b1b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egypt_list = list(df_copy['location'][df_copy['location'].str.contains('Egypt')].unique())\n",
    "len(egypt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_column_func(location_column):\n",
    "    for item in usa_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('United States')\n",
    "    \n",
    "    for item in india_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('India')\n",
    "\n",
    "    for item in uk_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('United Kingdom')\n",
    "\n",
    "    for item in brazil_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Brazil')\n",
    "\n",
    "    for item in spain_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Spain')   \n",
    "\n",
    "    for item in canda_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Canada') \n",
    "\n",
    "    for item in spain_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Spain') \n",
    "\n",
    "    for item in indonesia_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Indonesia') \n",
    "        \n",
    "    for item in ireland_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Ireland') \n",
    "        \n",
    "    for item in egypt_list:\n",
    "        if location_column.strip() == item:\n",
    "            return('Egypt') \n",
    "        \n",
    "    else:\n",
    "        return('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b0c4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['country'] = df_copy['location'].apply(country_column_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec785321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>skills</th>\n",
       "      <th>work_type</th>\n",
       "      <th>educational_background</th>\n",
       "      <th>experience_years</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>['Python', 'SQL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>691</td>\n",
       "      <td>Data Engineer- Python Pyspark</td>\n",
       "      <td>Virtusa</td>\n",
       "      <td>Chennai, Tamil Nadu, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>7+</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>692</td>\n",
       "      <td>Data Engineer with Pyspark</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['SQL', 'Spark', 'AWS', 'ETL']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>14+</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>693</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mercedes-Benz Malaysia</td>\n",
       "      <td>Puchong, Selangor, Malaysia</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...</td>\n",
       "      <td>remote</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>740</td>\n",
       "      <td>Data Engineer I</td>\n",
       "      <td>IntePros</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>741</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1+</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                          title                 company  \\\n",
       "0      1                   Data Analyst                    Meta   \n",
       "1      2                   Data Analyst                    Meta   \n",
       "2      3                   Data Analyst                    Meta   \n",
       "3      4                   Data Analyst                    Meta   \n",
       "4      5                Data Analyst II               Pinterest   \n",
       "..   ...                            ...                     ...   \n",
       "283  691  Data Engineer- Python Pyspark                 Virtusa   \n",
       "284  692     Data Engineer with Pyspark               Cognizant   \n",
       "285  693                  Data Engineer  Mercedes-Benz Malaysia   \n",
       "286  740                Data Engineer I                IntePros   \n",
       "287  741                  Data Engineer               Snap Inc.   \n",
       "\n",
       "                              location    source date_posted job_title_short  \\\n",
       "0                         New York, NY  LinkedIn  2025-04-14    Data Analyst   \n",
       "1                    San Francisco, CA  LinkedIn  2025-04-14    Data Analyst   \n",
       "2                      Los Angeles, CA  LinkedIn  2025-04-14    Data Analyst   \n",
       "3                       Washington, DC  LinkedIn  2025-04-14    Data Analyst   \n",
       "4                          Chicago, IL  LinkedIn  2025-04-16    Data Analyst   \n",
       "..                                 ...       ...         ...             ...   \n",
       "283         Chennai, Tamil Nadu, India  LinkedIn  2025-04-10   Data Engineer   \n",
       "284  Bangalore Urban, Karnataka, India  LinkedIn  2025-04-13   Data Engineer   \n",
       "285        Puchong, Selangor, Malaysia  LinkedIn  2025-04-16   Data Engineer   \n",
       "286                        Seattle, WA  LinkedIn  2025-04-15   Data Engineer   \n",
       "287                       Bellevue, WA  LinkedIn  2025-04-16   Data Engineer   \n",
       "\n",
       "                                                skills work_type  \\\n",
       "0    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "1    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "2    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "3    ['Tableau', 'Python', 'SQL', 'R', 'Machine Lea...       NaN   \n",
       "4                                    ['Python', 'SQL']       NaN   \n",
       "..                                                 ...       ...   \n",
       "283  ['Python', 'SQL', 'Kafka', 'Airflow', 'AWS', '...       NaN   \n",
       "284                     ['SQL', 'Spark', 'AWS', 'ETL']       NaN   \n",
       "285  ['Python', 'R', 'SQL', 'NoSQL', 'Power BI', 'D...    remote   \n",
       "286  ['Python', 'SQL', 'Redshift', 'MySQL', 'ETL', ...       NaN   \n",
       "287  ['Python', 'SQL', 'Spark', 'Hadoop', 'Airflow'...       NaN   \n",
       "\n",
       "     educational_background experience_years        country  \n",
       "0                      True               4+  United States  \n",
       "1                      True               4+  United States  \n",
       "2                      True               4+  United States  \n",
       "3                      True               4+  United States  \n",
       "4                      True               4+  United States  \n",
       "..                      ...              ...            ...  \n",
       "283                   False               7+          India  \n",
       "284                   False              14+          India  \n",
       "285                    True              NaN          Other  \n",
       "286                    True               3+  United States  \n",
       "287                    True               1+  United States  \n",
       "\n",
       "[288 rows x 12 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ca1307c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "United States     169\n",
       "India              41\n",
       "Other              28\n",
       "United Kingdom     23\n",
       "Brazil             10\n",
       "Canada              5\n",
       "Ireland             4\n",
       "Spain               3\n",
       "Indonesia           3\n",
       "Egypt               2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc37ac3",
   "metadata": {},
   "source": [
    "**9. Export First Final Dataframe As CSV File For Data Visualization And Insights With Power BI:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1109ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('final_cleaned_data_job_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4318a30",
   "metadata": {},
   "source": [
    "**10. Export Second Final Dataframe Which Contain Explode Skills List For Job Market Skills Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "955d91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "264b2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_list(string_list):\n",
    "    if isinstance(string_list, list):\n",
    "        return(string_list)\n",
    "    \n",
    "    if string_list == '[]':\n",
    "        return []\n",
    "    \n",
    "    else:\n",
    "        return(ast.literal_eval(string_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc29a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode['skills'] = df_explode['skills'].apply(explode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "803f36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode = df_explode.explode('skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "911a2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35b39eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode.to_csv('data_job_market_skills_explode_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
